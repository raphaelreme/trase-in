{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from byotrack import Video, VideoTransformConfig\n",
    "\n",
    "from byotrack.implementation.detector.stardist import StarDistDetector\n",
    "\n",
    "import skimage.io as iio\n",
    "from byotrack.video.transforms import ChannelSelect, ChannelAvg, ScaleAndNormalize \n",
    "from PIL import Image\n",
    "import numpy as np #can switch this out for pytorch at somepoint - notation is identical\n",
    "from roifile import ImagejRoi, ROI_TYPE, ROI_OPTIONS #for saving as an imageJ roi file\n",
    "from stardist.models import StarDist2D\n",
    "from stardist import random_label_cmap, _draw_polygons, export_imagej_rois\n",
    "import pathlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "tifpath = '/home/noah/Desktop/cellsegtest/segTestNew/shortStack_adjusted' #path to sequence of tiff files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reader funtion for tif sequences \n",
    "def Read_Data_TIFseq(vid_path):\n",
    "    # positions = (pd.read_csv(csv_path,usecols=['TrackID','t','x','y'])).values\n",
    "    vid = iio.ImageCollection(vid_path + '/*.tif').concatenate() #concatonate to numpyarray\n",
    "    # red_vid = iio.ImageCollection(red_vid_path + '/*.tif')\n",
    "    vid = vid.reshape(vid.shape[0], vid.shape[1], vid.shape[2], 1)\n",
    "    #vid = np.asarray([csbdeepNormaliser(frame) for frame in vid])\n",
    "    return vid\n",
    "\n",
    "\n",
    "def coordReshaper_IJ(coords): #reshaping for use with imageJ rois\n",
    "    coords_reshaped = []\n",
    "    for i in range(len(coords[0])):\n",
    "        xdata = coords[0][i]\n",
    "        ydata = coords[1][i]\n",
    "        coords_reshaped.append([ydata,xdata])\n",
    "    return coords_reshaped\n",
    "\n",
    "def reshape_all_rois(all_rois):\n",
    "    allROIs = []\n",
    "    for rois in all_rois:\n",
    "        roishaped = coordReshaper_IJ(rois)\n",
    "        allROIs.append(roishaped)\n",
    "    return allROIs\n",
    "\n",
    "def convert_to_ImageJ(allROIs):\n",
    "    ijrois = []\n",
    "    for roi in allROIs:\n",
    "        roimask = ImagejRoi.frompoints(roi)\n",
    "        roimask.roitype = ROI_TYPE.POLYGON\n",
    "        roimask.options |= ROI_OPTIONS.SHOW_LABELS\n",
    "        ijrois.append(roimask)\n",
    "    return ijrois\n",
    "\n",
    "\n",
    "def coordReshaper_CV_contours(coords):\n",
    "\n",
    "    '''\n",
    "    Reshape contours generated by StarDist for use with openCV's display contours function\n",
    "    '''\n",
    "\n",
    "    coords_reshaped = []\n",
    "    for contour in np.flip(coords,1): #hard to find this solution - coords need to be flipped, they are read clockwise by openCV and I guess this is not how they are written by StarDist. Results in contours plotted transposed from desired without flipping array.:)\n",
    "        for i in range(len(contour[0])):\n",
    "            coords_reshaped.append([contour[0][i], contour[1][i]]) #instead of flipping, these can be read y,x too [i.e. coords_reshaped.append([contour[1][i], contour[0][i]])]\n",
    "    \n",
    "    cv_format_contours = (np.array(coords_reshaped).reshape((-1,1,2)).astype(np.int32)) #https://stackoverflow.com/questions/14161331/creating-your-own-contour-in-opencv-using-python\n",
    "    return cv_format_contours\n",
    "\n",
    "def generate_contours(image, detector):\n",
    "    segmentation, data = detector._model.predict_instances(image, prob_thresh=detector.prob_threshold, nms_thresh=detector.nms_threshold, predict_kwargs={\"verbose\": 0})\n",
    "    contours = coordReshaper_CV_contours(data['coord'])\n",
    "    return contours\n",
    "\n",
    "\n",
    "def visualise_all_contours_cv(image, cvContours, colour = None):\n",
    "    '''\n",
    "    Takes contours in opencv format and plots them over image\n",
    "    https://stackoverflow.com/questions/57576686/how-to-overlay-segmented-image-on-top-of-main-image-in-python\n",
    "    '''\n",
    "\n",
    "    # image_contours = image.copy()\n",
    "    if colour == None:\n",
    "        colour = (0,255,255)\n",
    "    # Iterate over all contours\n",
    "    for i,c in enumerate(cvContours):\n",
    "        try:\n",
    "            \n",
    "            #for different colours - can define colour in this loop for each contour\n",
    "            \n",
    "            # Outline contour in that colour on main image, line thickness=1\n",
    "            cv2.drawContours(image,[c],-1,colour,1, cv2.LINE_8)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stardist():\n",
    "\n",
    "    def __init__(self, modelpath):\n",
    "        path = pathlib.Path(modelpath)\n",
    "        self._model = StarDist2D(None, path.name, str(path.parent))\n",
    "        self.prob_threshold: float = self._model.thresholds.prob\n",
    "        self.nms_threshold: float = self._model.thresholds.nms\n",
    "    \n",
    "    def detect(self, batch):\n",
    "        detections_list = []\n",
    "        data_list = []\n",
    "        for image in tqdm(batch):\n",
    "            segmentation, data = self._model.predict_instances(image, prob_thresh=self.prob_threshold, nms_thresh=self.nms_threshold, predict_kwargs={\"verbose\": 0})\n",
    "            detections_list.append(segmentation)\n",
    "            data_list.append(data)\n",
    "        return detections_list, data_list\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = Read_Data_TIFseq(tifpath)\n",
    "\n",
    "# normalize video\n",
    "mini = np.quantile(video, 0.005)\n",
    "maxi = np.quantile(video, 0.999)\n",
    "\n",
    "np.clip(video, mini, maxi, video)\n",
    "video = (video - mini) / (maxi - mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/noah/Desktop/STARDIST_CONFOCAL/NEWEST TdT MODELS/10X_IMAGES_ONLY\"\n",
    "\n",
    "detector = stardist(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/noah/Desktop/STARDIST_CONFOCAL/NEWEST TdT MODELS/10X_IMAGES_ONLY\"\n",
    "detector = StarDistDetector(model_path, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set model parameters for your dataset\n",
    "\n",
    "vidCopy = video[0:50] #test batch\n",
    "scale = 1\n",
    "\n",
    "global frameID\n",
    "global frame\n",
    "global frame_cv\n",
    "global contours\n",
    "\n",
    "frameID = 0\n",
    "frame = vidCopy[frameID].copy()\n",
    "frame_cv = cv2.normalize(src=frame, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "frame_cv = cv2.cvtColor(frame_cv, cv2.COLOR_GRAY2BGR)\n",
    "h, w = frame.shape[0:2]\n",
    "\n",
    "#initialise plotting parameters with default values - converted to 0-100 range for openCV trackbars\n",
    "probabilityThreshold = int(detector.prob_threshold*100) \n",
    "nmsThreshold = int(detector.nms_threshold*100)\n",
    "\n",
    "contours = generate_contours(frame, detector) \n",
    "\n",
    "# window_name = 'Frame', f'Frame {frameID} / {len(detections_sequence_test)} - Number of detections: {len(detections_sequence_test[i])}'\n",
    "window_name = 'Paramater Test - Segmentation   (Press Q to Quit)'\n",
    "\n",
    "try:\n",
    "\n",
    "    #create and rescale window\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(window_name, h*scale, w*scale)\n",
    "\n",
    "    #Frame Trackbar\n",
    "    def update_frame(x): #callback function for trackbar - default argument is the position of the track bar\n",
    "        global contours\n",
    "        global frame\n",
    "        global frame_cv\n",
    "\n",
    "        frame = vidCopy[x].copy()\n",
    "        frame_cv = cv2.normalize(src=frame, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "        frame_cv = cv2.cvtColor(frame_cv, cv2.COLOR_GRAY2BGR)\n",
    "        contours = generate_contours(frame, detector) \n",
    "    cv2.createTrackbar('Frame',window_name,0,len(vidCopy)-1,update_frame)\n",
    "\n",
    "    #Probability Trackbar\n",
    "    def update_probability_threshold(x):\n",
    "        detector.prob_threshold = (x+1)/100 \n",
    "        update_frame(frameID)\n",
    "    cv2.createTrackbar('Probability Threshold', window_name, probabilityThreshold, 99, update_probability_threshold)\n",
    "\n",
    "    #Overlap Trackbar\n",
    "    def update_overlap_threshold(x):\n",
    "        detector.nms_threshold = (x+1)/100\n",
    "        update_frame(frameID)\n",
    "    cv2.createTrackbar('Overlap Threshold', window_name, nmsThreshold, 99, update_overlap_threshold)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "\n",
    "        frameID = cv2.getTrackbarPos('Frame',window_name)\n",
    "        # cv2.imshow(window_name, video[frameID])\n",
    "        visualise_all_contours_cv(frame_cv, contours)\n",
    "        cv2.imshow(window_name, frame_cv)\n",
    "\n",
    "        probabilityThreshold = cv2.getTrackbarPos('Probability Threshold', window_name)/100\n",
    "        nmsThreshold = cv2.getTrackbarPos('Overlap Threshold', window_name)/100\n",
    "\n",
    "        #exit on q\n",
    "        if cv2.waitKey(5) == ord('q'):\n",
    "            # press q to terminate the loop\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print('Probability Threshold: ', probabilityThreshold)\n",
    "print('nms Threshold: ', nmsThreshold)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run detection on full video\n",
    "print('Probability Threshold: ', probabilityThreshold)\n",
    "print('nms Threshold: ', nmsThreshold)\n",
    "user_confirmation = input('Confirm parameters (y/n)')\n",
    "\n",
    "if user_confirmation == 'y':\n",
    "    # detections_sequence, data_sequence = detector.detect(video)\n",
    "    detections_sequence = detector.run(video)\n",
    "else:\n",
    "    print('Aborting Segmentstion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to a format for byotracks\n",
    "sequence = byotracks.Detections()\n",
    "np.flip(data_sequence[0]['points'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sequence[0]['points'][:,1][0] #shape is y,x for some reason... did I mess something up?\n",
    "# print(video[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord, points, prob = data_sequence[0]['coord'], data_sequence[0]['points'], data_sequence[0]['prob']\n",
    "plt.figure(figsize=(13,10))\n",
    "plt.ylim(1024, 0)\n",
    "plt.xlim(0,1024)\n",
    "plt.imshow(video[0].reshape(video[0].shape[0], video[0].shape[1]))\n",
    "#adding an imshow() plot here changes the way the axes count...\n",
    "_draw_polygons(coord, points, prob, show_dist=True)\n",
    "plt.figsize=(25,25)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(video[0].reshape(video[0].shape[0], video[0].shape[1]))\n",
    "plt.scatter(data_sequence[0]['points'][:,1], data_sequence[0]['points'][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation = detector.detect(video[0:5]) #, prob_thresh=detector.prob_threshold, nms_thresh=detector.nms_threshold, predict_kwargs={\"verbose\": 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmentation[0] #detections dataclass processes a frame of detections (mask) into centroids... this info is in data I believe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(segmentation[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_sequence[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from byotrack.api.detector.detections import relabel_consecutive\n",
    "import torch\n",
    "relabel_consecutive(torch.tensor(detections_sequence[0], dtype=torch.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_ids=range(len(video))\n",
    "for frame_id, detections in zip(frame_ids, detections_sequence):\n",
    "    detections.frame_id = frame_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(detections_sequence[0].position.flip(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspect all detections\n",
    "\n",
    "#to inspect previously loaded detections - simply load the detections from a np array first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save tracks as np array\n",
    "\n",
    "save_path_numpy = '/home/noah/Documents/NoahT2022/CodeRepos/Utopia/ExampleData/shortStack_adjusted/detections'\n",
    "detection_array = np.asarray(detections_sequence)\n",
    "np.save(save_path_numpy, detection_array, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save tracks as ImageJ ROIs\n",
    "# save_path_IJ = '/home/noah/Documents/NoahT2022/CodeRepos/Utopia/ExampleOutputs'\n",
    "\n",
    "# #detections objects do not contain polygon information, needs to be changed in byotracks or use stardist directly\n",
    "# IJreshaped_rois = reshape_all_rois(detections_sequence)\n",
    "# IJrois = convert_to_imageJ(IJreshaped_rois)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "\n",
    "#add code for inspecting detections (same as setting parameters but easier)\n",
    "\n",
    "#add code for saving detections in imageJ and numpy format\n",
    "\n",
    "#add colours to plots so overlapping segments can be distinguished\n",
    "\n",
    "#fix plotting so contours are continous and smoother - perhaps this was the case when I was using other methods..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imageJ roi style plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell seg style plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ijrois[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_overlays(image, ijrois)\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_n = cv2.normalize(src=image, dst=None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##cv contours\n",
    "# image32 = image2.astype('uint8') #opencv needs float32, images loaded as float64 here :)\n",
    "imagecv = cv2.cvtColor(img_n, cv2.COLOR_GRAY2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours,_ = cv2.findContours(imagecv[:,:,0],cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['coord'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvContours[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imagecv)\n",
    "print(imagecv.shape)\n",
    "print(imagecv.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(imagecv.shape, np.uint8)\n",
    "image_contours = imagecv.copy()\n",
    "# Iterate over all contours\n",
    "for i,c in enumerate(cvContours):\n",
    "    try:\n",
    "        # Find mean colour inside this contour by doing a masked mean\n",
    "        # mask = np.zeros(image_contours.shape, np.uint8)\n",
    "        # cv2.drawContours(mask,[c],-1,255, -1)\n",
    "        # DEBUG: cv2.imwrite(f\"mask-{i}.png\",mask)\n",
    "        # print(':)')\n",
    "        # mean,_,_,_ = cv2.mean(imagecv, mask=mask)\n",
    "        # DEBUG: print(f\"i: {i}, mean: {mean}\")\n",
    "\n",
    "        # Get appropriate colour for this label\n",
    "        # label = 2 if mean > 1.0 else 1\n",
    "        colour = (0,255,255)\n",
    "        # DEBUG: print(f\"Colour: {colour}\")\n",
    "        print(c)\n",
    "\n",
    "        # Outline contour in that colour on main image, line thickness=1\n",
    "        cv2.drawContours(image_contours,[c],-1,colour,1)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "        break\n",
    "try:\n",
    "    cv2.namedWindow('contour', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('contour',image_contours) \n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# try:\n",
    "#     cv2.drawContours(mask,[c],-1,255, -1)\n",
    "# except Exception as e:\n",
    "#     print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow('contour', cv2.WINDOW_NORMAL)\n",
    "cv2.imshow('contour', imagecv)\n",
    "cv2.waitKey(0)\n",
    "  \n",
    "# closing all open windows\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model paramters on data\n",
    "\n",
    "# Do not run this cell in order to keep the defaults prob_thresh and nms_thresh\n",
    "\n",
    "#TODO: add roi funtionality to this so plotting shows mask over image (better evaluation) Will need to edit both stardist detector and the detector class .detect() function to include polygon data and add imageJ ROI code\n",
    "vidCopy = video[0:50] #test batch\n",
    "scale = 1\n",
    "\n",
    "global frameID\n",
    "frameID = 0\n",
    "frame = video[frameID]\n",
    "h, w = frame.shape[0:2]\n",
    "global mask_glob\n",
    "detection_zero = detector.run([vidCopy[frameID]])\n",
    "mask_glob = (detection_zero[frameID].segmentation.numpy() != 0).astype(np.uint8) * 255\n",
    "\n",
    "# window_name = 'Frame', f'Frame {frameID} / {len(detections_sequence_test)} - Number of detections: {len(detections_sequence_test[i])}'\n",
    "window_name = 'Paramater Test - Segmentation   (Press Q to Quit)'\n",
    "\n",
    "try:\n",
    "\n",
    "    #create and rescale window\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(window_name, h*scale, w*scale)\n",
    "\n",
    "    #Frame Trackbar\n",
    "    def update_frame(x): #callback function for trackbar - default argument is the position of the track bar\n",
    "        detections = detector.detect(vidCopy[x][None, ...])\n",
    "        global mask_glob\n",
    "        mask_glob = (detections[0].segmentation.numpy() != 0).astype(np.uint8) * 255\n",
    "    cv2.createTrackbar('Frame',window_name,0,len(vidCopy)-1,update_frame)\n",
    "\n",
    "    #Probability Trackbar\n",
    "    def update_probability_threshold(x):\n",
    "        detector.prob_threshold = (x+1)/100 \n",
    "        update_frame(frameID)\n",
    "    cv2.createTrackbar('Probability Threshold', window_name, 0, 99, update_probability_threshold)\n",
    "\n",
    "    #Overlap Trackbar\n",
    "    def update_overlap_threshold(x):\n",
    "        detector.nms_threshold = (x+1)/100\n",
    "        update_frame(frameID)\n",
    "    cv2.createTrackbar('Overlap Threshold', window_name, 0, 99, update_overlap_threshold)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "\n",
    "        frameID = cv2.getTrackbarPos('Frame',window_name)\n",
    "        # cv2.imshow(window_name, video[frameID])\n",
    "        cv2.imshow(window_name, mask_glob)\n",
    "\n",
    "        probabilityThreshold = cv2.getTrackbarPos('Probability Threshold', window_name)/100\n",
    "        nmsThreshold = cv2.getTrackbarPos('Overlap Threshold', window_name)/100\n",
    "\n",
    "        #exit on q\n",
    "        if cv2.waitKey(5) == ord('q'):\n",
    "            # press q to terminate the loop\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "print('Prob: ', probabilityThreshold)\n",
    "print('nms: ', nmsThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roifile import ImagejRoi, ROI_TYPE, ROI_OPTIONS\n",
    "roi = ImagejRoi.frompoints(coords)\n",
    "roi.roitype = ROI_TYPE.POLYGON\n",
    "roi.options |= ROI_OPTIONS.SHOW_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reader funtion for tif sequences - handles reshaping and normalising (using the stardist recommended normaliser) (doesn't seem to perform that well)\n",
    "from csbdeep.utils import normalize as csbdeepNormaliser\n",
    "    \n",
    "def Read_Data_TIFseq(vid_path):\n",
    "    # positions = (pd.read_csv(csv_path,usecols=['TrackID','t','x','y'])).values\n",
    "    vid = iio.ImageCollection(vid_path + '/*.tif').concatenate() #concatonate to numpyarray #not concatenating allows for dynamic loading\n",
    "    # red_vid = iio.ImageCollection(red_vid_path + '/*.tif')\n",
    "    vid = vid.reshape(vid.shape[0], vid.shape[1], vid.shape[2], 1)\n",
    "    normalisedVid = np.asarray([csbdeepNormaliser(frame) for frame in vid])\n",
    "    return normalisedVid\n",
    "\n",
    "video = Read_Data_TIFseq(tifpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "from scipy.ndimage.morphology import binary_dilation, binary_erosion\n",
    "from skimage.morphology import disk\n",
    "import random\n",
    "import pandas as pd\n",
    "from matplotlib.ticker import NullLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vis from cellseg\n",
    "\n",
    "def get_bounding_box(masks):\n",
    "    indices = np.where(masks != 0)\n",
    "    values = masks[indices[0], indices[1]]\n",
    "    maskframe = pd.DataFrame(np.transpose(np.array([indices[0], indices[1], values]))).rename(columns = {0:\"y\", 1:\"x\", 2:\"id\"})\n",
    "    bb_mins = maskframe.groupby('id').agg({'y': 'min', 'x': 'min'}).to_records(index = False).tolist()\n",
    "    bb_maxes = maskframe.groupby('id').agg({'y': 'max', 'x': 'max'}).to_records(index = False).tolist()\n",
    "    \n",
    "    return bb_mins, bb_maxes\n",
    "\n",
    "\n",
    "\n",
    "def compute_snippet_bounds(minY, minX, maxY, maxX, Y, X):\n",
    "    if minX < 0: minX = 0\n",
    "    if minY < 0: minY = 0\n",
    "    if maxX >= X: maxX = X - 1\n",
    "    if maxY >= Y: maxY = Y - 1\n",
    "        \n",
    "    return minY, minX, maxY, maxX\n",
    "\n",
    "\n",
    "def extract_snippet(Y, X, masks, mins, maxes):\n",
    "    \n",
    "    minY, minX, maxY, maxX = compute_snippet_bounds(mins[0] - 1, mins[1] - 1, maxes[0] + 1, maxes[1] + 1, Y, X)\n",
    "        \n",
    "    return masks[(minY):(maxY), (minX):(maxX)], minY, minX, maxY, maxX\n",
    "\n",
    "def get_mask_ids(masks):\n",
    "    maskids = list(np.unique(masks))\n",
    "    maskids.remove(0)\n",
    "    maskids.sort()\n",
    "    \n",
    "    return maskids\n",
    "\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    colors = [(int(i[0] * 255), int(i[1] * 255), int(i[2] * 255)) for i in colors]\n",
    "    random.shuffle(colors)\n",
    "    return colors\n",
    "\n",
    "def generate_mask_outlines(masks):\n",
    "    \n",
    "    #first compute bounding boxes\n",
    "    maskids = get_mask_ids(masks)\n",
    "    num_masks = len(maskids)\n",
    "\n",
    "    bb_mins, bb_maxes = get_bounding_box(masks)\n",
    "\n",
    "    Y, X = masks.shape\n",
    "\n",
    "    output_im = np.zeros(masks.shape, dtype = np.uint32)\n",
    "\n",
    "    struc = disk(1)\n",
    "    for i, maskid in enumerate(maskids):\n",
    "\n",
    "        currreg, minY, minX, maxY, maxX = extract_snippet(Y, X, masks, bb_mins[i], bb_maxes[i])\n",
    "\n",
    "        mask_snippet = (currreg == maskid)\n",
    "        interior = binary_erosion(mask_snippet, struc)\n",
    "        boundary = mask_snippet ^ interior\n",
    "\n",
    "        pix_to_update = np.nonzero(boundary)\n",
    "\n",
    "        pix_X = np.array([min(j + minX, X) for j in pix_to_update[1]])\n",
    "        pix_Y = np.array([min(j + minY, Y) for j in pix_to_update[0]])\n",
    "\n",
    "        output_im[pix_Y, pix_X] = maskid\n",
    "\n",
    "    return output_im\n",
    "    \n",
    "def overlay_outlines_and_save(image, masks, outputpath, figsize, colors = None):\n",
    "    \n",
    "    auto_show = False\n",
    "    _, ax = plt.subplots(1, figsize=figsize)\n",
    "\n",
    "    maskids = get_mask_ids(masks)\n",
    "    num_masks = len(maskids)\n",
    "\n",
    "    # Generate random colors\n",
    "    colors = colors or random_colors(num_masks)\n",
    "\n",
    "    bb_mins, bb_maxes = get_bounding_box(masks)\n",
    "\n",
    "    #rgb_im = cv2.cvtColor(nimage, cv2.COLOR_GRAY2RGB)\n",
    "    rgb_im = image\n",
    "\n",
    "    rgb_im = rgb_im.astype(np.uint8)\n",
    "\n",
    "    Y, X = masks.shape\n",
    "\n",
    "    for i, maskid in enumerate(maskids):\n",
    "\n",
    "        currreg, minY, minX, maxY, maxX = extract_snippet(Y, X, masks, bb_mins[i], bb_maxes[i])\n",
    "        mask_snippet = (currreg == maskid)\n",
    "\n",
    "\n",
    "        color = colors[i]\n",
    "        #if i < 10:\n",
    "        #    print(color)\n",
    "        #    plt.imshow(mask_snippet)\n",
    "       #     plt.show()\n",
    "       #     plt.close()\n",
    "        pix_to_update = np.nonzero(mask_snippet)\n",
    "\n",
    "        #minY, minX, maxY, maxX = compute_snippet_bounds(bb_mins[i][0] - 1, bb_mins[i][1] - 1, bb_maxes[i][0] + 1, bb_maxes[i][1] + 1, Y, X)\n",
    "\n",
    "        pix_X = np.array([min(j + minX, X) for j in pix_to_update[1]])\n",
    "        pix_Y = np.array([min(j + minY, Y) for j in pix_to_update[0]])\n",
    "\n",
    "        rgb_im[pix_Y, pix_X, :] = color\n",
    "        #rgb_im[pix_Y, pix_X, 1] = 255\n",
    "        #rgb_im[pix_Y, pix_X, 2] = 255\n",
    "\n",
    "    ax.axis('off')\n",
    "    img = ax.imshow(rgb_im)\n",
    "    # This is needed to remove all whitespace\n",
    "    plt.gca().set_axis_off()\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "                hspace = 0, wspace = 0)\n",
    "    plt.margins(0,0)\n",
    "    plt.gca().xaxis.set_major_locator(NullLocator())\n",
    "    plt.gca().yaxis.set_major_locator(NullLocator())\n",
    "    plt.savefig(outputpath, dpi=75)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskplotter(image, segmentation, colors = None):\n",
    "\n",
    "    # image=image.reshape(image.shape[0], image.shape[1])\n",
    "    masks = segmentation\n",
    "    maskids = get_mask_ids(masks)\n",
    "    num_masks = len(maskids)\n",
    "\n",
    "    # Generate random colors\n",
    "    colors = colors or random_colors(num_masks)\n",
    "\n",
    "    bb_mins, bb_maxes = get_bounding_box(masks)\n",
    "\n",
    "    #rgb_im = cv2.cvtColor(nimage, cv2.COLOR_GRAY2RGB)\n",
    "    rgb_im = image\n",
    "\n",
    "    rgb_im = rgb_im.astype(np.uint8)\n",
    "    print(rgb_im.shape)\n",
    "\n",
    "    Y, X = masks.shape\n",
    "\n",
    "    for i, maskid in enumerate(maskids):\n",
    "\n",
    "        currreg, minY, minX, maxY, maxX = extract_snippet(Y, X, masks, bb_mins[i], bb_maxes[i])\n",
    "        mask_snippet = (currreg == maskid)\n",
    "\n",
    "\n",
    "        color = colors[i]\n",
    "        #if i < 10:\n",
    "        #    print(color)\n",
    "        #    plt.imshow(mask_snippet)\n",
    "        #     plt.show()\n",
    "        #     plt.close()\n",
    "        pix_to_update = np.nonzero(mask_snippet)\n",
    "\n",
    "        #minY, minX, maxY, maxX = compute_snippet_bounds(bb_mins[i][0] - 1, bb_mins[i][1] - 1, bb_maxes[i][0] + 1, bb_maxes[i][1] + 1, Y, X)\n",
    "\n",
    "        pix_X = np.array([min(j + minX, X) for j in pix_to_update[1]])\n",
    "        pix_Y = np.array([min(j + minY, Y) for j in pix_to_update[0]])\n",
    "\n",
    "        rgb_im[pix_Y, pix_X, :] = color\n",
    "\n",
    "    return rgb_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = np.zeros(image.shape)\n",
    "img2 = cv2.merge((dummy,image,dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (segmentation != 0).astype(np.uint8) * 255\n",
    "masksim  = generate_mask_outlines(mask)\n",
    "colorMaskIm = maskplotter(img2, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "path = '/home/noah/Desktop/cellsegtest/segTestNew/shortStack_adjusted/camera2_NDTiffStack0002.tif'\n",
    "image = np.array(tifffile.imread(path))\n",
    "image = image.reshape(image.shape[0], image.shape[1], 1)\n",
    "print(image.shape)\n",
    "shape = image.shape\n",
    "SHAPE = (shape[1], shape[2], shape[0])\n",
    "image = np.transpose(image, (1, 2, 0))\n",
    "image = image.reshape(SHAPE)\n",
    "\n",
    "image.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_outlines_and_save(image, mask, '/home/noah/Documents/NoahT2022/CodeRepos/Utopia/ExampleData', (30,30), colors = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1)\n",
    "ax.axis('off')\n",
    "img = ax.imshow(colorMaskIm)\n",
    "# This is needed to remove all whitespace\n",
    "plt.gca().set_axis_off()\n",
    "plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "            hspace = 0, wspace = 0)\n",
    "plt.margins(0,0)\n",
    "plt.gca().xaxis.set_major_locator(NullLocator())\n",
    "plt.gca().yaxis.set_major_locator(NullLocator())\n",
    "# plt.savefig(outputpath, dpi=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newim = masksim + image.reshape(image.shape[0], image.shape[1])\n",
    "print(masksim.shape)\n",
    "print(image.shape)\n",
    "print(newim.shape)\n",
    "plt.imshow(newim)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgmask = cv2.merge((newim,dummy,dummy))\n",
    "plt.imshow(imgmask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx=~(masksim==0)\n",
    "# newim = np.where(idx, image[::,0], image[::,0])\n",
    "# newim2 = np.putmask(image[::,0], idx, 255)\n",
    "\n",
    "indx = idx.nonzero()\n",
    "newim3 = image.reshape(image.shape[0], image.shape[1])\n",
    "newim3 = img2\n",
    "print(newim3.shape)\n",
    "newim3[indx][2] = 0.5\n",
    "plt.imshow(newim3[::])\n",
    "plt.show()\n",
    "\n",
    "print(newim3.max())\n",
    "print(newim3.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newim.shape\n",
    "plt.imshow(idx)\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(newim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byostar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
