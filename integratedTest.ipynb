{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from byotrack import Video, VideoTransformConfig\n",
    "\n",
    "import skimage.io as iio\n",
    "from byotrack.video.transforms import ChannelSelect, ChannelAvg, ScaleAndNormalize \n",
    "from PIL import Image\n",
    "import numpy as np #can switch this out for pytorch at somepoint - notation is identical\n",
    "\n",
    "\n",
    "icy_path = \"/home/noah/Documents/icy-2.4.2.0-all\"\n",
    "tifpath = '/home/noah/Desktop/cellsegtest/segTestNew/shortStack_adjusted' #path to sequence of tiff files\n",
    "\n",
    "#for video playback only\n",
    "fps = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reader funtion for tif sequences - handles reshaping and normalising (using the stardist recommended normaliser) (doesn't seem to perform that well)\n",
    "from csbdeep.utils import normalize as csbdeepNormaliser\n",
    "    \n",
    "def Read_Data_TIFseq(vid_path):\n",
    "    # positions = (pd.read_csv(csv_path,usecols=['TrackID','t','x','y'])).values\n",
    "    vid = iio.ImageCollection(vid_path + '/*.tif').concatenate() #concatonate to numpyarray\n",
    "    # red_vid = iio.ImageCollection(red_vid_path + '/*.tif')\n",
    "    vid = vid.reshape(vid.shape[0], vid.shape[1], vid.shape[2], 1)\n",
    "    normalisedVid = np.asarray([csbdeepNormaliser(frame) for frame in vid])\n",
    "    return normalisedVid\n",
    "\n",
    "video = Read_Data_TIFseq(tifpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation of the whole video with opencv\n",
    "\n",
    "for i, frame in enumerate(video):\n",
    "    try:\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.setWindowTitle('Frame', f'Frame {i} / {len(video)}')\n",
    "\n",
    "        # Press Q on keyboard to  exit\n",
    "        key = cv2.waitKey(1000 // fps) & 0xFF\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "        if cv2.getWindowProperty(\"Frame\", cv2.WND_PROP_VISIBLE) <1:\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n",
    "#warning with opencv QOBject::moveToThread can be fixed: https://stackoverflow.com/questions/52337870/python-opencv-error-current-thread-is-not-the-objects-thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from byotrack.implementation.detector.stardist import StarDistDetector\n",
    "from byotrack.implementation.detector.wavelet import WaveletDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the detector object with its hyper parameters\n",
    "model_path = \"/home/noah/Desktop/STARDIST_CONFOCAL/NEWEST TdT MODELS/10X_IMAGES_ONLY\"\n",
    "detector = StarDistDetector(model_path, batch_size=5)\n",
    "#TODO: figure out batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model parameters\n",
    "detections_sequence_test = detector.run(video[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#TODO: add roi funtionality to this so plotting shows mask over image (better evaluation) Will need to edit both stardist detector and the detector class .detect() function to include polygon data and add imageJ ROI code\n",
    "vidCopy = video[0:50] #test batch\n",
    "scale = 1\n",
    "\n",
    "global frameID\n",
    "frameID = 0\n",
    "frame = video[frameID]\n",
    "h, w = frame.shape[0:2]\n",
    "global mask_glob\n",
    "mask_glob = (detections_sequence_test[frameID].segmentation.numpy() != 0).astype(np.uint8) * 255\n",
    "\n",
    "# window_name = 'Frame', f'Frame {frameID} / {len(detections_sequence_test)} - Number of detections: {len(detections_sequence_test[i])}'\n",
    "window_name = 'Paramater Test - Segmentation   (Press Q to Quit)'\n",
    "\n",
    "try:\n",
    "\n",
    "    #create and rescale window\n",
    "    cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(window_name, h*scale, w*scale)\n",
    "\n",
    "    #Frame Trackbar\n",
    "    def update_frame(x): #callback function for trackbar - default argument is the position of the track bar\n",
    "        detections = detector.detect(vidCopy[x][None, ...])\n",
    "        global mask_glob\n",
    "        mask_glob = (detections[0].segmentation.numpy() != 0).astype(np.uint8) * 255\n",
    "    cv2.createTrackbar('Frame',window_name,0,len(vidCopy)-1,update_frame)\n",
    "\n",
    "    #Probability Trackbar\n",
    "    def update_probability_threshold(x):\n",
    "        detector.prob_threshold = x/100\n",
    "        update_frame(frameID)\n",
    "    cv2.createTrackbar('Probability Threshold', window_name, 0, 99, update_probability_threshold)\n",
    "\n",
    "    #Overlap Trackbar\n",
    "    def update_overlap_threshold(x):\n",
    "        detector.nms_threshold = x/100\n",
    "        update_frame(frameID)\n",
    "    cv2.createTrackbar('Overlap Threshold', window_name, 0, 99, update_overlap_threshold)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "\n",
    "        frameID = cv2.getTrackbarPos('Frame',window_name)\n",
    "        # cv2.imshow(window_name, video[frameID])\n",
    "        cv2.imshow(window_name, mask_glob)\n",
    "\n",
    "        probabilityThreshold = cv2.getTrackbarPos('Probability Threshold', window_name)/100\n",
    "        nmsThreshold = cv2.getTrackbarPos('Overlap Threshold', window_name)/100\n",
    "\n",
    "        #exit on q\n",
    "        if cv2.waitKey(5) == ord('q'):\n",
    "            # press q to terminate the loop\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "print('Prob: ', probabilityThreshold)\n",
    "print('nms: ', nmsThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set hyperparameters manually on the video\n",
    "# Use w/x to move backward/forward in the video\n",
    "# Use c/v to update k (the main hyperparameter)\n",
    "# You can restard with another scale/min_area\n",
    "\n",
    "\n",
    "i = 0\n",
    "prob_speed = 0.1\n",
    "nms_speed = 0.2\n",
    "while True:\n",
    "    try:\n",
    "        frame = video[i]\n",
    "        detections = detector.detect(frame[None, ...])[0][0]\n",
    "        print(detections)\n",
    "        mask = (detections.segmentation.numpy() != 0).astype(np.uint8) * 255\n",
    "        print('a')\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('Frame', mask)\n",
    "        cv2.setWindowTitle('Frame', f'Frame {i} / {len(video)} - prob={detector.prob_threshold}, nms={detector.nms_threshold} - Num detections: {detections.length}')\n",
    "        print('b')\n",
    "        # Press Q on keyboard to  exit\n",
    "        key = cv2.waitKey() & 0xFF\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "        if cv2.getWindowProperty(\"Frame\", cv2.WND_PROP_VISIBLE) <1:\n",
    "            break\n",
    "\n",
    "        if key == ord(\"a\"):\n",
    "            i = (i - 1) % len(video)\n",
    "\n",
    "        if key == ord(\"d\"):\n",
    "            i = (i + 1) % len(video)\n",
    "\n",
    "        if key == ord(\"c\"):\n",
    "            detector.prob_threshold = detector.prob_threshold * (1 - prob_speed)\n",
    "\n",
    "        if key == ord(\"v\"):\n",
    "            detector.prob_threshold = detector.prob_threshold * (1 + prob_speed)\n",
    "\n",
    "        if key == ord(\"b\"):\n",
    "            detector.nms_threshold = detector.nms_threshold * (1 - nms_speed)\n",
    "\n",
    "        if key == ord(\"n\"):\n",
    "            detector.nms_threshold = detector.nms_threshold * (1 + nms_speed)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "byostar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
