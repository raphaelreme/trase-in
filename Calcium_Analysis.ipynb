{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "\n",
    "from SCHyA import SCHyA as hy\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "import byotrack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacement for extract fluorescence in schya\n",
    "\n",
    "def extract_intensities(video, tracks, patch_size):\n",
    "    \"\"\"Extract intensities at the track location from the given video\"\"\"\n",
    "    intensities = np.zeros((len(tracks), len(video)))\n",
    "    for frame_id, frame in enumerate(tqdm.tqdm(video)):\n",
    "        for track_id, track in enumerate(tracks):\n",
    "            point = track[frame_id]\n",
    "\n",
    "            i = int(point[0] - patch_size / 2)\n",
    "            j = int(point[1] - patch_size / 2)\n",
    "\n",
    "            intensities[track_id, frame_id] = frame[max(0, i) : i + patch_size, max(0, j) : j + patch_size].mean()\n",
    "    return intensities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused\n",
    "#input path to your .csv from ICY\n",
    "csv_path = '/home/noah/Documents/NoahT2022/Data/SingleCell_Tracking/ALI_comp/redTracks.csv'\n",
    "\n",
    "positions = byotrack.Track.tensorize(byotrack.Track.load(\"tracks.pth\")).numpy()\n",
    "positions_reshaped = np.transpose(positions, (1,0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load videos\n",
    "#gcamp_path = \"../pasteur/data/long movies_tracks/6X_green_1000_2bin.avi\"\n",
    "#tdtomato_path = \"../pasteur/data/long movies_tracks/6X_red_1000_2bin.avi\"\n",
    "gcamp_path = '/home/noah/Desktop/cellsegtest/segTestNew/shortStack_adjusted'\n",
    "tdtomato_path ='/home/noah/Desktop/cellsegtest/segTestNew/shortStack_adjusted'\n",
    "\n",
    "gcamp_video = byotrack.Video(gcamp_path)[:100]\n",
    "tdtomato_video = byotrack.Video(tdtomato_path)[:100]\n",
    "\n",
    "# # To be deleted, we should keep clearer names\n",
    "# vid = gcamp_video\n",
    "# red_vid = tdtomato_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload tracks\n",
    "\n",
    "tracks = byotrack.Track.load(\"tracks.pt\")",
    "positions, vid, red_vid = hy.Read_Data_TIFseq_byo(numpy_path, green_channel_path, red_channel_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract calcium and control intensities\n",
    "\n",
    "intensities_raw = extract_intensities(vid, tracks, 9)\n",
    "\n",
    "intensities_red = extract_intensities(red_vid, tracks, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 709 is an interesting tracks with 2/3 firings\n",
    "\n",
    "plt.plot(intensities_raw[709])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(intensities_red[709])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused\n",
    "positions, vid, red_vid = hy.Read_Data_TIFseq_byo(numpy_path, vid_path, red_vid_path)\n",
    "positions_reshaped = np.transpose(positions, (1,0,2)) #https://stackoverflow.com/questions/68700008/difference-between-just-reshaping-and-reshaping-and-getting-transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should be useless now\n",
    "\n",
    "def npy_remove_incomplete_tracks(tracks_reshaped):\n",
    "\n",
    "    complete_tracks = []\n",
    "    incomplete_tracks = []\n",
    "    indexes = []\n",
    "\n",
    "    for i, track in enumerate(tracks_reshaped):\n",
    "        hasNaN = np.isnan(track).any()\n",
    "        if hasNaN:\n",
    "            print('nan')\n",
    "            incomplete_tracks.append(track)\n",
    "            indexes.append(i)\n",
    "        else:\n",
    "            complete_tracks.append(track)\n",
    "    \n",
    "    return np.asarray(complete_tracks), [incomplete_tracks, indexes]\n",
    "\n",
    "posit_corrected, removed_tracks = npy_remove_incomplete_tracks(positions_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused\n",
    "\n",
    "#Extract the fluorescence intensity in the GCaMP channel throughout the video for each neuron\n",
    "\n",
    "#size of ROI\n",
    "# dim = 9\n",
    "dim=9\n",
    "# subROI_Circle_size = 4\n",
    "subROI_Circle_size = 3\n",
    "LookBack = 1 #resistance of tracking to movement i.e. how quickly a tracked neuron can move before position resets\n",
    "\n",
    "#Extract large ROI and remove points too close to edge\n",
    "intensities_raw, posit_corrected_raw = hy.Extract_Fluorescence(positions_reshaped, vid, dimention = dim)\n",
    "\n",
    "#extract signal from subROI around neuron\n",
    "# intensities1, posit_corrected1, neuron_pts = hy.SingleCellIntensities(vid, posit_corrected_raw, dim, subROI_Circle_size, LookBack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO using the sequence loader gives frames in wrong format for cv2 rgb2gray function - need to run conversion either in data loader or in single cell function (or both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Figure1 subplots \n",
    "import matplotlib as mpl\n",
    "keyCells = range(30)\n",
    "keyCells = [4,8,12,29]\n",
    "\n",
    "mpl.rcParams.update({'font.size': 18, \"text.usetex\": True})\n",
    "fig, axs = plt.subplots(2, len(keyCells), sharex =True, sharey=True, figsize=(30, 5))\n",
    "\n",
    "\n",
    "# axs.xlabel(\"x\", fontsize=80)\n",
    "# axs.ylabel(\"y\", fontsize=80)\n",
    "# axs.xlim(-3, 3)\n",
    "# axs.ylim(-1.05, 1.05)\n",
    "\n",
    "styles = [\"o\", \"^\", \"s\", \"X\", \"*\"]\n",
    "default_color_iter = plt.rcParams[\"axes.prop_cycle\"]()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "axs[0,0].set_ylabel('Raw Signals')\n",
    "axs[1,0].set_ylabel('Sub ROI Signals')\n",
    "\n",
    "for i, neuron in enumerate(keyCells):\n",
    "    axs[0,i].set_title('Neuron: ' + str(neuron))\n",
    "\n",
    "    axs[0,i].plot(intensities_raw[neuron])\n",
    "    axs[0,i].grid()\n",
    "    axs[1,i].grid()\n",
    "    axs[1,i].plot(intensities_raw[neuron]) #these might not line up if there is an issue with points being removed!\n",
    "    \n",
    "# fig.text(0.5, -0.05, 'Frames', ha='center', fontsize = 30)\n",
    "# fig.text(0.04, 0.5, 'common Y', va='center', rotation='vertical')\n",
    "# plt.savefig(\"/home/noah/Documents/NoahT2022/utopiaFigures/rawvsROI_signals.svg\", format = \"svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CaSignal = hy.ICAdecorr(intensities_raw, intensities_red, 0.5, 10)\n",
    "\n",
    "#Plot Signal\n",
    "for i in range(len(CaSignal)):\n",
    "    plt.plot(CaSignal[i])\n",
    "plt.title('Extracted Calcium Signal Plot')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Ca Intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(CaSignal[709])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hy.plot_heatmap(CaSignal, 'Heatmap of Extracted Calcium Signal', 'Ca Signal Intensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Polynomial Degree\n",
    "poly_deg = 1\n",
    "\n",
    "detrended = hy.detrend_all(intensities_raw.tolist(), poly_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(detrended[709])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1e-4 #Tune threshold for coherence to gaussian distribution - need to use detrended data with this function\n",
    "noise = []\n",
    "firing_neurons = []\n",
    "\n",
    "for intensities in detrended:\n",
    "    a, b = scipy.stats.normaltest(intensities)\n",
    "    if b >= alpha:\n",
    "        noise.append(intensities)\n",
    "    else:\n",
    "        firing_neurons.append(intensities)\n",
    "        \n",
    "print(len(noise), len(firing_neurons))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused\n",
    "\n",
    "alpha = 1e-5 #Tune threshold for coherence to gaussian distribution - need to use detrended data with this function\n",
    "detrended2, posit_corrected2, removed = hy.Gaussian_noise_filter(detrended, alpha, posit_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, 4, sharex = 'col', sharey='row', figsize=(20, 20))\n",
    "for i, cell in enumerate(firing_neurons[0:16]):\n",
    "    if i<4:\n",
    "        axs[0,i].plot(cell)\n",
    "    elif i >=4 and i < 8:\n",
    "        axs[1,i-4].plot(cell)\n",
    "    elif i >=8 and i < 12:\n",
    "        axs[2,i-8].plot(cell)\n",
    "    elif i >=12 and i < 16:\n",
    "        axs[3,i-12].plot(cell)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Raster Plot using CAIMAN's FOOPSI function - Denoising and Deconvolution\n",
    "\n",
    "#foopsi\n",
    "Foopsi_ca, spikes_signal_dR = hy.FOOPSI_all(firing_neurons)\n",
    "\n",
    "#Extract Raster Plot Data\n",
    "\n",
    "#Threshold (could use a theoretical value for threshold! - See CAIMAN Docs - but trial & error is also fine)\n",
    "#USE FOOPSI EVALUATION CELL TO TUNE THIS PARAMETER (0.04 works well)\n",
    "spike_thresh_dR = 0.4\n",
    "\n",
    "raster_array_dR = hy.Find_Raster_adaptive2(spikes_signal_dR, spike_thresh_dR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display Results\n",
    "\n",
    "#plot raster\n",
    "#zero values from way array was made array give large syncronous train at start of the signal - should fix (.append method?)\n",
    "plt.figure(2)\n",
    "plt.eventplot(raster_array_dR,linelengths = 0.6)\n",
    "plt.ylabel('Neuron')\n",
    "plt.xlabel('Frame')\n",
    "plt.title('Raster Plot of Neural Activity of Hydra')\n",
    "plt.xlim((1,len(raster_array_dR[0])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(tracks[:,2]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasNaNs(index):\n",
    "    i = index\n",
    "    hasNaN = np.isnan(tracks[:,i]).any()\n",
    "    return hasNaN\n",
    "\n",
    "def hasNaNs2(column):\n",
    "    # i = index\n",
    "    hasNaN = np.isnan(column).any()\n",
    "    return hasNaN\n",
    "\n",
    "# any(np.isnan(tracks[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_tracks = []\n",
    "incomplete_tracks = []\n",
    "indexes = []\n",
    "for i in range(tracks.shape[1]):\n",
    "    hasNaN = np.isnan(tracks[:,i]).any()\n",
    "    if hasNaN:\n",
    "        incomplete_tracks.append(tracks[:,i])\n",
    "        indexes.append(i)\n",
    "    else:\n",
    "        complete_tracks.append(tracks[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(indexes)\n",
    "print('number Removed: ', len(indexes))\n",
    "print('num kept: ', len(complete_tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completetracks = [hasNaNs2(track[:,i]) for  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tracks.shape)\n",
    "\n",
    "df = pd.DataFrame(data = tracks.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(hasNaNs2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = tracks.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape tracks\n",
    "posit_corrected = hy.remove_incomplete_tracks(tracks, num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(posit_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = (pd.read_csv(csv_path,usecols=['TrackID','t','x','y']))\n",
    "\n",
    "trackIDs = positions.TrackID.unique()\n",
    "grouped = positions.groupby(['TrackID'])\n",
    "\n",
    "posit = np.asanyarray([grouped.get_group(neuron).loc[:, ['x', 'y']].values for neuron in trackIDs], dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = pd.read_csv(csv_path, dtype = 'object', converters={'0': pd.eval})\n",
    "# positions.drop(positions.columns[0], axis=1, inplace=True)\n",
    "\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posit_corrected = complete_tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(posit_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, red, green = hy.Read_Data_TIFseq(vid_path, red_vid_path, csv_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
